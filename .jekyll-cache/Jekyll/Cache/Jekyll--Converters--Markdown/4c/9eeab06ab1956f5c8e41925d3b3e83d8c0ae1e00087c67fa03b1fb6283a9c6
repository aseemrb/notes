I"	<p>There are five very popular factorizations for matrices. In the literature, the word <code class="highlighter-rouge">decomposition</code> is often used instead of <code class="highlighter-rouge">factorization</code>.</p>

<h2 id="lu-decomposition">LU decomposition</h2>
<p>This is the lower-upper (LU) decomposition applicable to square matrices $A$, and the factorization can be viewed as the matrix form of <a href="https://en.wikipedia.org/wiki/Gaussian_elimination">Gaussian elimination</a>. We write</p>

\[A = LU\]

<p>where $L$ and $U$ are lower and upper triangular matrices.</p>

<p>If $A$ is symmetric and <a href="../positive-definite-matrices/">positive definite</a>, then we can find $U=L^T$ and have</p>

\[A=LL^T\]

<p>This decomposition is used in algorithms to</p>
<ul>
  <li>solve a square system of linear equations,</li>
  <li>compute the inverse of a matrix, and</li>
  <li>compute the determinant of a matrix.</li>
</ul>

<h2 id="qr-decomposition">QR decomposition</h2>
<p>Here we factor an $m\times n$ matrix $A$ into an $m\times m$ <a href="../orthogonal-matrices/">orthogonal matrix</a> $Q$ and an $m\times n$ triangular matrix $R$. A popular method to compute this factorization is the <a href="https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process">Gram-Schmidt process</a>. If $A$ is square then $Q$ is unique.</p>

<p>The QR decomposition makes it easy to solve a system of equations $Ax = b$ without inverting the matrix $A$. Since $Q$ is orthogonal, we have $Q^T Q = I$, so $Ax=b$ is equivalent to $Rx = Q^T b$, which is easier to solve since R is triangular. We write</p>

\[A = QR\]

<p>where $Q$ is orthogonal and $R$ is upper-triangular.</p>

<h2 id="spectral-decomposition">Spectral decomposition</h2>
<p>Also called eigendecomposition, this is a factorization of a square matrix into <a href="../eigenvalues-eigenvectors">eigenvalues and eigenvectors</a>, $A=VDV^{-1}$, where $D$ is a diagonal matrix with the eigenvalues of $A$ and the columns of $V$ are the corresponding eigenvectors.</p>

<p>Although this factorization is possible for any square matrix with linearly independent eigenvectors, it is usually used for symmetric matrices $S$. Since the eigenvectors can be made orthonormal for a symmetric matrix, the factorization is written as:</p>

\[S=Q\Lambda Q^T\]

:ET